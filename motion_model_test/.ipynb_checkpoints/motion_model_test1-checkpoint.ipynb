{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 사용할 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.python.keras.layers.convolutional import Conv2D\n",
    "from tensorflow.python.keras.layers.convolutional import MaxPooling2D\n",
    "from tensorflow.python.keras.layers.core import Activation\n",
    "from tensorflow.python.keras.layers.core import Flatten\n",
    "from tensorflow.python.keras.layers.core import Dropout\n",
    "from tensorflow.python.keras.layers.core import Dense\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.python.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "dfile = \"temp_img.npz\"\n",
    "images = np.load(dfile)[\"train\"]\n",
    "\n",
    "d2file = \"temp_img2.npz\"\n",
    "images2=np.load(d2file)['train']\n",
    "\n",
    "print('images2 shape',images2.shape)\n",
    "plt.imshow(images2)\n",
    "\n",
    "emp=np.vstack((images,images2))\n",
    "print(\"stacked shape\",emp.shape)\n",
    "\n",
    "plt.ion()\n",
    "plt.figure()\n",
    "images=np.reshape(images,(180,240,3))\n",
    "print( emp[180:360,:240,:].shape)\n",
    "print(np.array_equal(images2, emp[180:360,:240,:]))\n",
    "plt.imshow(emp[180:360,:240,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load load model data -> success!\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "x_train = np.empty((180,240, 3))\n",
    "y_train = np.empty((0, 3))\n",
    "print(y_train.shape)\n",
    "\n",
    "training_data = glob.glob('/home/pirl/Documents/motion_1213ver/*.npz')\n",
    "#print(training_data)\n",
    "\n",
    "for single_npz in training_data:\n",
    "    with np.load(single_npz) as data:\n",
    "        #print(data.files)\n",
    "        x = data['train']\n",
    "        y = data['trining_label']\n",
    "        temp=cv2.cvtColor(x, cv2.COLOR_BGR2GRAY) # convert color to gray\n",
    "        print(x.shape,temp.shape)\n",
    "   # x = np.reshape(temp, ( -1, 3, 120, 1))\n",
    "    \n",
    "    x_train = np.vstack((x_train, x))\n",
    "    y_train = np.vstack((y_train, y))\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "# train test split, 7:3\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3, random_state = 42)\n",
    "\n",
    "y_train = y_train[:,:]\n",
    "y_test = y_test[:,:]\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-f739f833daaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_npz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#print(data.files)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trining_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/frcnn1/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 return format.read_array(bytes,\n\u001b[1;32m    261\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/frcnn1/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;31m# not correctly instantiate zero-width string dtypes; see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;31m# https://github.com/numpy/numpy/pull/6430\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load motion model data --> fail \n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train = np.empty((0,180,240,3))\n",
    "y_train = np.empty((0, 3))\n",
    "print(y_train.shape)\n",
    "\n",
    "training_data = glob.glob('/home/pirl/Documents/motion_1213ver/*.npz')\n",
    "#print(training_data)\n",
    "idx=1\n",
    "#total_data=[]\n",
    "for single_npz in training_data:\n",
    "    with np.load(single_npz) as data:\n",
    "        #print(data.files)\n",
    "        x = data['train']\n",
    "        y = data['trining_label']\n",
    "        \n",
    "        #print(x.shape, y.shape)\n",
    "    x = np.reshape(x, (-1,180, 240, 3))\n",
    "    #x = np.transpose(x, (0,2,3,1))\n",
    "    y_temp=np.empty((0,3))\n",
    "    for i in range(x.shape[0]):\n",
    "        y_temp=np.vstack((y_temp,y))\n",
    "    \n",
    "    #total_data.append(x)\n",
    "    x_train = np.vstack((x_train, x))\n",
    "    y_train = np.vstack((y_train, y_temp))\n",
    "    #print(idx)\n",
    "    idx+=1\n",
    "print(x_train.shape) #, total_data.shape)\n",
    "print(y_train.shape)\n",
    "#train test split, 7:3\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3, random_state = 42)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3)\n",
    "# x_train = x_train[:6369]; y_train=y_train[:6369]\n",
    "# x_test = x_train[6369:]; y_test = y_train[6369:]\n",
    "\n",
    "#x_train, y_train, x_test, y_test = x_train[:6369], y_train[:6369], x_train[6369:], y_train[6369:]\n",
    "\n",
    "y_train = y_train[:,:]\n",
    "y_test = y_test[:,:]\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 240, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3)\n",
      "['train', 'trining_label']\n",
      "(547020, 240, 3) (3,)\n",
      "['train', 'trining_label']\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e14b966d8f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_npz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trining_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/frcnn1/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 return format.read_array(bytes,\n\u001b[1;32m    261\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/frcnn1/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;31m# not correctly instantiate zero-width string dtypes; see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;31m# https://github.com/numpy/numpy/pull/6430\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load motion model data --> fail \n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train2 = np.empty((180,240,3))\n",
    "y_train2 = np.empty((0, 3))\n",
    "print(y_train2.shape)\n",
    "\n",
    "training_data = glob.glob('/home/pirl/Documents/motion_1213ver/*.npz')\n",
    "#print(training_data)\n",
    "idx=1\n",
    "#total_data=[]\n",
    "for single_npz in training_data:\n",
    "    with np.load(single_npz) as data:\n",
    "        print(data.files)\n",
    "        x = data['train']\n",
    "        y = data['trining_label']\n",
    "        \n",
    "        print(x.shape, y.shape)\n",
    "    #x = np.reshape(x, (-1,180, 240, 3))\n",
    "    #x = np.transpose(x, (0,2,3,1))\n",
    "    y_temp=np.empty((0,3))\n",
    "    for i in range(x.shape[0]//180):\n",
    "        y_temp=np.vstack((y_temp,y))\n",
    "    \n",
    "    #total_data.append(x)\n",
    "    x_train2 = np.vstack((x_train2, x))\n",
    "    y_train2 = np.vstack((y_train2, y_temp))\n",
    "    #print(idx)\n",
    "    idx+=1\n",
    "print(x_train2.shape) #, total_data.shape)\n",
    "print(y_train2.shape)\n",
    "#train test split, 7:3\n",
    "#x_train2, x_test2, y_train2, y_test2 = train_test_split(x_train, y_train, test_size=0.3, random_state = 42)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3)\n",
    "# x_train = x_train[:6369]; y_train=y_train[:6369]\n",
    "# x_test = x_train[6369:]; y_test = y_train[6369:]\n",
    "\n",
    "#x_train, y_train, x_test, y_test = x_train[:6369], y_train[:6369], x_train[6369:], y_train[6369:]\n",
    "\n",
    "\n",
    "\n",
    "y_train2 = y_train2[:,:]\n",
    "y_test2 = y_test2[:,:]\n",
    "\n",
    "print(x_train2.shape, y_train2.shape)\n",
    "print(x_test2.shape, y_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[6369:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "dfile = \"temp_img.npz\"\n",
    "images = np.load(dfile)[\"train\"]\n",
    "images.shape\n",
    "plt.ion()\n",
    "plt.figure()\n",
    "plt.imshow(images.transpose((0,1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 240, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1fb567fc18>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAHECAYAAAD742TKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAXY0lEQVR4nO3df4xlZ33f8c+33pgU0sgmHiNn19RutKSBKAVr6rpFjQhuiqER60pBMqrCilra/jApadIGk0h1/yT9EdqoDdImuDYSNbEI1FblJnFdUlSpGMaEgH+EeGVSe7HDDiKQKEhQw7d/zNl0WGa99txn9p47fr2kq7n3uefOPLvHd/X2c849U90dAAAW9+eWPQEAgP1CWAEADCKsAAAGEVYAAIMIKwCAQYQVAMAgexZWVXVdVX22qk5U1c179XMAAOai9uI6VlV1QZLfT/KjSU4m+USSN3f3w8N/GADATBzYo+97dZIT3f1YklTVB5IcSbJjWF1yySV9xRVX7NFUAADGeeCBB77Y3Ws7PbdXYXUwyRPbHp9M8te2b1BVx5IcS5KXvvSl2djY2KOpAACMU1X/52zP7dU5VrXD2Lccc+zu49293t3ra2s7Rh8AwErZq7A6meTybY8PJXlyj34WAMAs7FVYfSLJ4aq6sqouTHJDkrv36GcBAMzCnpxj1d1PV9XbkvxmkguS3NrdD+3FzwIAmIu9Onk93X1Pknv26vsDAMyNK68DAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGCQXYdVVV1eVR+pqkeq6qGqevs0/uKqureqHp2+XjxuugAA87XIitXTSX6mu38gyTVJbqqqlye5Ocl93X04yX3TYwCAfW/XYdXdT3X3J6f7f5LkkSQHkxxJcvu02e1Jrl90kgAAq2DIOVZVdUWSVyW5P8lLuvupZCu+klx6ltccq6qNqtrY3NwcMQ0AgKVaOKyq6ruS/HqSn+ruP362r+vu49293t3ra2tri04DAGDpFgqrqvqObEXV+7v7Q9PwF6rqsun5y5KcWmyKAACrYZFPBVaS9yZ5pLt/cdtTdyc5Ot0/muSu3U8PAGB1HFjgta9O8hNJPlNVn5rGfi7Ju5LcWVU3Jnk8yZsWmyIAwGrYdVh19/9KUmd5+trdfl8AgFXlyusAAIMIKwCAQYQVAMAgwgoAYBBhBQAwiLACABhEWAEADCKsAAAGEVYAAIMIKwCAQYQVAMAgwgoAYBBhBQAwiLACABhEWAEADCKsAAAGEVYAAIMIKwCAQYQVAMAgwgoAYBBhBQAwiLACABhEWAEADCKsAAAGEVYAAIMIKwCAQYQVAMAgwgoAYBBhBQAwiLACABhEWAEADCKsAAAGEVYAAIMIKwCAQYQVAMAgwgoAYBBhBQAwyMJhVVUXVNXvVNV/nR5fWVX3V9WjVfVrVXXh4tMEAJi/EStWb0/yyLbHv5Dk3d19OMkfJblxwM8AAJi9hcKqqg4l+TtJfnV6XElem+SD0ya3J7l+kZ8BALAqFl2x+ndJfjbJN6fH35Pky9399PT4ZJKDO72wqo5V1UZVbWxubi44DQCA5dt1WFXVjyU51d0PbB/eYdPe6fXdfby717t7fW1tbbfTAACYjQMLvPbVSd5YVW9I8p1JvjtbK1gXVdWBadXqUJInF58mAMD87XrFqrvf2d2HuvuKJDck+R/d/feSfCTJj0+bHU1y18KzBABYAXtxHat3JPnpqjqRrXOu3rsHPwMAYHYWORT4Z7r7t5P89nT/sSRXj/i+AACrxJXXAQAGEVYAAIMIKwCAQYQVAMAgwgoAYBBhBQAwiLACABhEWAEADCKsAAAGEVbAIDXdAJ6/hBUAwCDCCgBgkCG/hBkg6WVPAGDprFgBAAwirAAABhFWAACDCCtgBZyfSzm4YASwKGEFADCIsAIAGMTlFoCZOH0QbqfLNpyfSzm4YASwKCtWAACDWLECZmIG60XPtGgG8CxYsQIAGERYAQAMIqwAAAYRVgAAgzh5HeC0dvY6sBgrVgAAg1ixAvgzVqqAxVixAgAYRFgBAAwirAAABhFWAACDCCsAgEGEFQDAIMIKGKSmG8Dzl7ACABhEWAEADLJQWFXVRVX1war6vap6pKr+elW9uKrurapHp68Xj5osAMCcLbpi9e+T/EZ3/+UkfyXJI0luTnJfdx9Oct/0GABg39t1WFXVdyf54STvTZLu/np3fznJkSS3T5vdnuT6RScJrADnrgMstGL1l5JsJvlPVfU7VfWrVfWiJC/p7qeSZPp66U4vrqpjVbVRVRubm5sLTAMAYB4WCasDSa5K8p7uflWSP81zOOzX3ce7e72719fW1haYBgDAPCwSVieTnOzu+6fHH8xWaH2hqi5LkunrqcWmCACwGnYdVt39h0meqKrvn4auTfJwkruTHJ3Gjia5a6EZAquhpxvA89iBBV//k0neX1UXJnksyVuzFWt3VtWNSR5P8qYFfwYAwEpYKKy6+1NJ1nd46tpFvi8AwCpadMUKYOI4IIBfaQMAMIiwAgAYRFgBAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBnA813YB9TVgBAAwirAAABjmw7AkAPC/0sicAnA9WrAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAwirAAABhFWS1fTDQBYdcIKAGAQYQUAMMiBZU9gfnY6LNd7+PP28nsDAOeTFSsAgEEWCquq+qdV9VBVPVhVd1TVd1bVlVV1f1U9WlW/VlUXjplq7XDbC73DDQDg3HYdVlV1MMk/SbLe3T+Y5IIkNyT5hSTv7u7DSf4oyY0jJgoAMHeLHgo8kOTPV9WBJC9M8lSS1yb54PT87UmuX/BnTKwkAQDztuuw6u7PJ/k3SR7PVlB9JckDSb7c3U9Pm51McnCn11fVsaraqKqNzc3N3U4DAGA2FjkUeHGSI0muTPK9SV6U5PU7bLrj0lJ3H+/u9e5eX1tb2+00AABmY5FDgX8ryee6e7O7/2+SDyX5G0kumg4NJsmhJE8uOEcAgJWwSFg9nuSaqnphVVWSa5M8nOQjSX582uZokrsWmyIAwGpY5Byr+7N1kvonk3xm+l7Hk7wjyU9X1Ykk35PkvQPmCQAwewtdeb27b0lyyxnDjyW5epHvCwCwilx5HQBgEGEFADCIsAIAGERYAQAMIqwAAAYRVgAAgwgrAIBBhBUAwCDCCgBgEGEFADDIQr/SBoCZqnMOJN3nYybwvGLFCgBgECtWAPvRty1GWZ2C88GKFQDAIMIKAGAQYQUAMIhzrADmprZ9gs8n92ClWLECABhEWAEADOJQIMDcOPwHK8uKFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAwirAAABhFWAEtT0w3YL4QVAMAgLhAKsDQuBAr7jRUrAIBBhBUAwCDCCgBgEGEFADCIsAIAGERYAQAMIqwAAAYRVgAAgwgrAIBBzhlWVXVrVZ2qqge3jb24qu6tqkenrxdP41VVv1RVJ6rq01V11V5OHgBgTp7NitVtSa47Y+zmJPd19+Ek902Pk+T1SQ5Pt2NJ3jNmmgAA83fOsOrujyb50hnDR5LcPt2/Pcn128bf11s+luSiqrps1GQBAOZst+dYvaS7n0qS6eul0/jBJE9s2+7kNPZtqupYVW1U1cbm5uYupwEAMB+jT16vHcZ2/PXt3X28u9e7e31tbW3wNAAAzr/dhtUXTh/im76emsZPJrl823aHkjy5++kBAKyO3YbV3UmOTvePJrlr2/hbpk8HXpPkK6cPGQIA7HcHzrVBVd2R5DVJLqmqk0luSfKuJHdW1Y1JHk/ypmnze5K8IcmJJF9N8tY9mDMAwCydM6y6+81neeraHbbtJDctOikAgFXkyusAAIMIKwCAQYQVAMAgwgoAYBBhBQAwiLACABhEWAEADCKsAAAGEVYAAIMIKwCAQYQVAMAgwgoAYBBhBQAwiLACABhEWAEADCKsAAAGEVYAAIMIKwCAQYQVAMAgwgoAYBBhBQAwiLACABhEWAEADCKsAAAGEVYAAIMIKwCAQYQVAMAgwgoAYBBhBQAwiLACABhEWAEADCKsAAAGEVYAAIMIKwCAQYQVAMAgwgoAYBBhBQAwyDnDqqpurapTVfXgtrF/XVW/V1WfrqoPV9VF2557Z1WdqKrPVtXr9mriAABz82xWrG5Lct0ZY/cm+cHu/qEkv5/knUlSVS9PckOSV0yv+eWqumDYbAEAZuycYdXdH03ypTPGfqu7n54efizJoen+kSQf6O6vdffnkpxIcvXA+QIAzNaIc6z+fpL/Nt0/mOSJbc+dnMa+TVUdq6qNqtrY3NwcMA0AgOVaKKyq6ueTPJ3k/aeHdtisd3ptdx/v7vXuXl9bW1tkGgAAs3Bgty+sqqNJfizJtd19Op5OJrl822aHkjy5++kBAKyOXa1YVdV1Sd6R5I3d/dVtT92d5IaqekFVXZnkcJKPLz5NAID5O+eKVVXdkeQ1SS6pqpNJbsnWpwBfkOTeqkqSj3X3P+zuh6rqziQPZ+sQ4U3d/Y29mjywD9W2Mwp6xzMJAGaregb/cK2vr/fGxsaypwHMgbACZq6qHuju9Z2e2/U5VgB7Q0wBq8uvtAEAGERYAQAMIqwAAAYRVgAAgzh5HZgX564DK8yKFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAsaq6bZf7fc/H7AQYQUAMMiBZU8A2Gd62RPYY/v9zwcsxIoVAMAgwgoAYJBzhlVV3VpVp6rqwR2e+2dV1VV1yfS4quqXqupEVX26qq7ai0kDPG9Ubd2AlfBsVqxuS3LdmYNVdXmSH03y+Lbh1yc5PN2OJXnP4lMEAFgN5wyr7v5oki/t8NS7k/xsvvVUziNJ3tdbPpbkoqq6bMhMgeWouMTAMnVv3YCVsKtzrKrqjUk+392/e8ZTB5M8se3xyWlsp+9xrKo2qmpjc3NzN9MAAJiV5xxWVfXCJD+f5F/s9PQOYzv+r1Z3H+/u9e5eX1tbe67TAM6X3nYD4Bnt5jpW35fkyiS/W1snVB5K8smqujpbK1SXb9v2UJInF50kAMAqeM4rVt39me6+tLuv6O4rshVTV3X3Hya5O8lbpk8HXpPkK9391NgpAwDM07O53MIdSf53ku+vqpNVdeMzbH5PkseSnEjyK0n+8ZBZAgCsgHMeCuzuN5/j+Su23e8kNy0+LQCA1ePK6wAAgwgrAIBBhBUAwCDCCgBgEGEFADCIsAIAGERYAQAMIqwAAAYRVgAAgwgrAIBBhBUAwCDCCgBgEGEF+1VNN/Y/+xpmQ1gBAAxyYNkTAPZIL3sCnDd9ernKTodls2IFADCIFSuAlWelCubCihUAwCDCCgBgEGEFADCIsAIAGERYwX7jYpEASyOsAAAGcbkF2G988h5gaaxYAQAMIqwAVpXz6WB2hBUAwCDCCgBgECevA6wqH1SA2bFiBQAwiLACABhEWAEADCKszgufiQb2gH9aYHaEFQDAIMIKAGAQl1s4L3wmmvPo9KEh/9nt/7+L/frnghVmxQoAYJBzhlVV3VpVp6rqwTPGf7KqPltVD1XVv9o2/s6qOjE997rnNp2KszFhQR0rGaf5uwDOs2dzKPC2JP8hyftOD1TVjyQ5kuSHuvtrVXXpNP7yJDckeUWS703y36vqZd39jdETBwCYm3OuWHX3R5N86Yzhf5TkXd39tWmbU9P4kSQf6O6vdffnkpxIcvWzn07H/2ICAKtqt+dYvSzJ36yq+6vqf1bVX53GDyZ5Ytt2J6exb1NVx6pqo6o2Njc3dzkNAID52G1YHUhycZJrkvzzJHdW1dlOjtpx+am7j3f3enevr62t7XIaAADzsduwOpnkQ73l40m+meSSafzybdsdSvLkYlMEAFgNuw2r/5LktUlSVS9LcmGSLya5O8kNVfWCqroyyeEkHx8xUQCAuTvnpwKr6o4kr0lySVWdTHJLkluT3DpdguHrSY52dyd5qKruTPJwkqeT3OQTgcDSbT9JwWdjgD1UWz20XOvr672xsbHsaQD7lbACBqqqB7p7fafn/EobYP8TU8B54lfaAAAMIqwAAAZxKBBYHc6VAmbOihUAwCDCCgBgEGEFADCIsAIAGERYAQAMIqwAAAYRVrBfVb718gQA7DlhBQAwiAuEwn7lApr73+kVSfsaZsOKFQDAIFasgNVhZQaYOStWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYxOUWAFZVu0IozI0VKwCAQYQVAMAgDgUCrKqaDgE6EgizYcUKAGAQK1bA6qht963S+DuAGbJiBQAwiLACWFWVb13FA5ZOWAEADCKsAAAGEVbwfOLQ0TOr2roB7JKwAgAYxOUW4PnEx/OfWa/YX9CKTReeD6xYAQAMYsUKWB1WaICZs2IFADCIsAIAGERYAQAMIqwAAAapnsHHi6tqM8mfJvnisufCUJfEPt1P7M/9xf7cX+zP8+svdvfaTk/MIqySpKo2unt92fNgHPt0f7E/9xf7c3+xP+fDoUAAgEGEFQDAIHMKq+PLngDD2af7i/25v9if+4v9OROzOccKAGDVzWnFCgBgpQkrAIBBZhFWVXVdVX22qk5U1c3Lng/PXVX9QVV9pqo+VVUb09iLq+reqnp0+nrxsufJ2VXVrVV1qqoe3Da24z6sLb80vWc/XVVXLW/m7OQs+/NfVtXnp/fpp6rqDduee+e0Pz9bVa9bzqw5m6q6vKo+UlWPVNVDVfX2adx7dGaWHlZVdUGS/5jk9UlenuTNVfXy5c6KXfqR7n7ltmup3Jzkvu4+nOS+6THzdVuS684YO9s+fH2Sw9PtWJL3nKc58uzdlm/fn0ny7ul9+sruvidJpn9zb0jyiuk1vzz928x8PJ3kZ7r7B5Jck+Smab95j87M0sMqydVJTnT3Y9399SQfSHJkyXNijCNJbp/u357k+iXOhXPo7o8m+dIZw2fbh0eSvK+3fCzJRVV12fmZKc/GWfbn2RxJ8oHu/lp3fy7JiWz928xMdPdT3f3J6f6fJHkkycF4j87OHMLqYJIntj0+OY2xWjrJb1XVA1V1bBp7SXc/lWz9o5Dk0qXNjt062z70vl1db5sODd267fC8/blCquqKJK9Kcn+8R2dnDmFVO4y5BsTqeXV3X5Wt5eebquqHlz0h9pT37Wp6T5LvS/LKJE8l+bfTuP25Iqrqu5L8epKf6u4/fqZNdxizT8+DOYTVySSXb3t8KMmTS5oLu9TdT05fTyX5cLYOI3zh9NLz9PXU8mbILp1tH3rfrqDu/kJ3f6O7v5nkV/L/D/fZnyugqr4jW1H1/u7+0DTsPTozcwirTyQ5XFVXVtWF2TqB8u4lz4nnoKpeVFV/4fT9JH87yYPZ2o9Hp82OJrlrOTNkAWfbh3cnecv0yaNrknzl9OEI5uuMc2z+brbep8nW/ryhql5QVVdm64Tnj5/v+XF2VVVJ3pvkke7+xW1PeY/OzIFlT6C7n66qtyX5zSQXJLm1ux9a8rR4bl6S5MNb7/scSPKfu/s3quoTSe6sqhuTPJ7kTUucI+dQVXckeU2SS6rqZJJbkrwrO+/De5K8IVsnOX81yVvP+4R5RmfZn6+pqldm65DQHyT5B0nS3Q9V1Z1JHs7Wp89u6u5vLGPenNWrk/xEks9U1aemsZ+L9+js+JU2AACDzOFQIADAviCsAAAGEVYAAIMIKwCAQYQVAMAgwgoAYBBhBQAwyP8D8FPUxeS/W9QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(x_train[0].shape)\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "#x_temp=np.reshape(x_train,(-1,180,240,3))\n",
    "#print(x_temp.shape)\n",
    "for i in range(plt_row*plt_col):\n",
    "    \n",
    "    sub_plt = axarr[int(i/plt_row), int(i%plt_col)]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_train[i])\n",
    "    #sub_plt.imshow(x_train[i].reshape(240, 180,3))\n",
    "    #print(x_temp[i*180:180*(i+1),:,:].shape)\n",
    "    label = np.argmax(y_train)\n",
    "                      \n",
    "    if label == 2 :\n",
    "        direction = 'left'\n",
    "    elif label == 1:\n",
    "        direction = 'right'\n",
    "    elif label == 0:\n",
    "        direction = 'forward'\n",
    "\n",
    "    sub_plt_title = str(label) + \" : \" + direction\n",
    "    sub_plt.set_title(sub_plt_title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image size = 160 x 320\n",
    "def posla_net():\n",
    "    \n",
    "    # model setting\n",
    "    H = 240\n",
    "    W = 180\n",
    "    CH = 3\n",
    "\n",
    "    inputShape = (H, W, CH)\n",
    "\n",
    "    activation = 'relu'\n",
    "    keep_prob_conv = 0.25\n",
    "    keep_prob_dense = 0.5\n",
    "\n",
    "    #init = 'glorot_normal'\n",
    "    #init = 'he_normal'\n",
    "    init = 'he_uniform'\n",
    "    chanDim = -1\n",
    "    classes = 3\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # CONV => RELU => POOL\n",
    "    model.add(Conv2D(3, (3, 3), padding=\"valid\", input_shape=inputShape, kernel_initializer=init, activation=activation))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(9, (3, 3), padding=\"valid\", kernel_initializer=init, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(18, (3, 3), padding=\"valid\", kernel_initializer=init, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), padding=\"valid\", kernel_initializer=init, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(80, kernel_initializer=init, activation=activation))\n",
    "    model.add(Dropout(keep_prob_dense))\n",
    "    \n",
    "    model.add(Dense(15, kernel_initializer=init, activation=activation))\n",
    "    model.add(Dropout(keep_prob_dense))\n",
    "    \n",
    "    # softmax classifier\n",
    "    model.add(Dense(classes , activation = 'softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = posla_net()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils import plot_model\n",
    "plot_model(model, to_file= 'video_net_plot.png', show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 모델 파라미터 셋팅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "적은 수의 이미지 데이터가 존재할 경우 데이터를 늘리는 용도로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "# EPOCHS = 50\n",
    "# INIT_LR = 1e-3\n",
    "# BS = 32\n",
    "# split_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 50\n",
    "INIT_LR = 1e-4\n",
    "BS = 256\n",
    "split_ratio = 0.2\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binary = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "hist = model.fit(x_train, y_train, \n",
    "                 epochs=EPOCHS, batch_size=BS, \n",
    "                 validation_split=split_ratio, \n",
    "                 verbose = 1\n",
    "                 ,callbacks=[reduce_lr]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.title('model loss')\n",
    "plt.plot(hist.history['loss'], label=\"loss\")\n",
    "plt.plot(hist.history['val_loss'], label=\"val_loss\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.ylim((0,2))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('model accuracy')\n",
    "plt.plot(hist.history['acc'], label=\"acc\")\n",
    "plt.plot(hist.history['val_acc'], label=\"val_acc\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.ylim((0.4, 1))\n",
    "\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 모델 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l_model = load_model('./model_data/VGG_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=BS)\n",
    "print('## evaluation loss and_metrics ##')\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat_idx = np.random.choice(x_test.shape[0], 10)\n",
    "xhat = x_test[xhat_idx]\n",
    "\n",
    "yhat_classes = model.predict_classes(xhat)\n",
    "\n",
    "for i in range(10):\n",
    "    print('True : ' + str(np.argmax(y_test[xhat_idx[i]])) + ', Predict : ' + str(yhat_classes[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 최종 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_total = np.vstack((x_train, x_test))\n",
    "y_total = np.vstack((y_train, y_test))\n",
    "\n",
    "print(x_total.shape)\n",
    "print(y_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "INIT_LR = 1e-4\n",
    "BS = 256\n",
    "split_ratio = 0.2\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist = model.fit(x_total, y_total, \n",
    "                 epochs=EPOCHS, batch_size=BS, \n",
    "                 #validation_split=split_ratio, \n",
    "                 verbose = 1\n",
    "                 ,callbacks=[reduce_lr]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=BS)\n",
    "print('## evaluation loss and_metrics ##')\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat_idx = np.random.choice(x_test.shape[0], 10)\n",
    "xhat = x_test[xhat_idx]\n",
    "\n",
    "yhat_classes = model.predict_classes(xhat)\n",
    "\n",
    "for i in range(10):\n",
    "    print('True : ' + str(np.argmax(y_test[xhat_idx[i]])) + ', Predict : ' + str(yhat_classes[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import model_from_yaml\n",
    "\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"motion_model_demoV2.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"motion_model_demoV2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('motion_save_demo1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('motion_save_demo1.h5')\n",
    "# summarize model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"motion_model_demoV2-1.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"motion_model_demoV2-1.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(r'motion_model_demoV2-1.yaml') as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    fruits_list = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "    print(fruits_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    yamlPath =path[0]\n",
    "    h5Path = path[1]\n",
    "\n",
    "    yaml_file1 = open(yamlPath, 'r')\n",
    "    loaded_model_yaml = yaml_file1.read()\n",
    "    yaml_file1.close()\n",
    "    model = model_from_yaml(loaded_model_yaml)\n",
    "\n",
    "    # load weights into new model\n",
    "    model.load_weights(h5Path)\n",
    "    model._make_predict_function()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(['/home/pirl/A1-PONATA/Hayoung/motion_model_test/motion_model_demoV2-1.yaml',\n",
    "            '/home/pirl/A1-PONATA/Hayoung/motion_model_test/motion_model_demoV2-1.h5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import model_from_yaml\n",
    "\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"motion_model_demoV2.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"motion_model_demoV2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_model(['motion_model_demoV1.yaml','motion_model_demoV1.h5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
