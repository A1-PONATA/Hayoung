{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 사용할 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.python.keras.layers.convolutional import Conv2D\n",
    "from tensorflow.python.keras.layers.convolutional import MaxPooling2D\n",
    "from tensorflow.python.keras.layers.core import Activation\n",
    "from tensorflow.python.keras.layers.core import Flatten\n",
    "from tensorflow.python.keras.layers.core import Dropout\n",
    "from tensorflow.python.keras.layers.core import Dense\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4622981600106460800\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12161013025861999808\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 12648448\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8254765847696499629\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080, pci bus id: 0000:17:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6716833792\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2427167009528639935\n",
      "physical_device_desc: \"device: 1, name: GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 18335749225274995433\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3)\n",
      "0.0 min 100\n",
      "0.0 min 200\n",
      "1.0 min 300\n",
      "2.0 min 400\n",
      "3.0 min 500\n",
      "5.0 min 600\n",
      "8.0 min 700\n",
      "10.0 min 800\n",
      "12.0 min 900\n",
      "15.0 min 1000\n",
      "18.0 min 1100\n",
      "22.0 min 1200\n",
      "25.0 min 1300\n",
      "29.0 min 1400\n",
      "33.0 min 1500\n",
      "39.0 min 1600\n",
      "43.0 min 1700\n",
      "48.0 min 1800\n",
      "54.0 min 1900\n",
      "60.0 min 2000\n",
      "66.0 min 2100\n",
      "72.0 min 2200\n",
      "78.0 min 2300\n",
      "85.0 min 2400\n",
      "92.0 min 2500\n",
      "100.0 min 2600\n",
      "107.0 min 2700\n",
      "115.0 min 2800\n",
      "123.0 min 2900\n",
      "132.0 min 3000\n",
      "140.0 min 3100\n",
      "149.0 min 3200\n",
      "159.0 min 3300\n",
      "168.0 min 3400\n",
      "178.0 min 3500\n",
      "188.0 min 3600\n",
      "198.0 min 3700\n",
      "209.0 min 3800\n",
      "220.0 min 3900\n",
      "231.0 min 4000\n",
      "243.0 min 4100\n",
      "254.0 min 4200\n",
      "266.0 min 4300\n",
      "279.0 min 4400\n",
      "292.0 min 4500\n",
      "304.0 min 4600\n",
      "318.0 min 4700\n",
      "331.0 min 4800\n",
      "345.0 min 4900\n",
      "359.0 min 5000\n",
      "373.0 min 5100\n",
      "388.0 min 5200\n",
      "403.0 min 5300\n",
      "418.0 min 5400\n",
      "433.0 min 5500\n",
      "449.0 min 5600\n",
      "465.0 min 5700\n",
      "481.0 min 5800\n",
      "498.0 min 5900\n",
      "514.0 min 6000\n",
      "531.0 min 6100\n",
      "549.0 min 6200\n",
      "567.0 min 6300\n",
      "585.0 min 6400\n",
      "603.0 min 6500\n",
      "621.0 min 6600\n",
      "640.0 min 6700\n",
      "659.0 min 6800\n",
      "679.0 min 6900\n",
      "698.0 min 7000\n",
      "718.0 min 7100\n",
      "738.0 min 7200\n",
      "759.0 min 7300\n",
      "780.0 min 7400\n",
      "801.0 min 7500\n",
      "822.0 min 7600\n",
      "844.0 min 7700\n",
      "866.0 min 7800\n",
      "888.0 min 7900\n",
      "910.0 min 8000\n",
      "933.0 min 8100\n",
      "956.0 min 8200\n",
      "980.0 min 8300\n",
      "1004.0 min 8400\n",
      "1029.0 min 8500\n",
      "1054.0 min 8600\n",
      "1079.0 min 8700\n",
      "1103.0 min 8800\n",
      "1128.0 min 8900\n",
      "1154.0 min 9000\n",
      "1179.0 min 9100\n",
      "1205.0 min 9200\n",
      "1232.0 min 9300\n",
      "1258.0 min 9400\n",
      "1286.0 min 9500\n",
      "1313.0 min 9600\n",
      "1341.0 min 9700\n",
      "1369.0 min 9800\n",
      "1398.0 min 9900\n",
      "1427.0 min 10000\n",
      "(10000, 320, 320, 3)\n",
      "(7000, 320, 320, 3) (7000, 3)\n",
      "(3000, 320, 320, 3) (3000, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train = np.empty((0, 320, 320, 3))\n",
    "y_train = np.empty((0, 3))\n",
    "print(y_train.shape)\n",
    "t= time.time()\n",
    "training_data = glob.glob('/home/pirl/Documents/selected_motion_data10000/*.npz')\n",
    "#print(training_data)\n",
    "idx=1\n",
    "for single_npz in training_data:\n",
    "    with np.load(single_npz) as data:\n",
    "        #print(data.files)\n",
    "        x = data['train']\n",
    "        y = data['training_labels']\n",
    "        #print(x.shape)\n",
    "    x = np.reshape(x, (-1, 320, 320,3))\n",
    "    \n",
    "    x_train = np.vstack((x_train, x))\n",
    "    y_train = np.vstack((y_train, y))\n",
    "    if idx % 100 ==0:\n",
    "        print(str((time.time()-t)//60)+\" min\",idx)\n",
    "    idx+=1\n",
    "print(x_train.shape)\n",
    "# train test split, 7:3\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3, random_state = 42)\n",
    "\n",
    "y_train = y_train[:,:]\n",
    "y_test = y_test[:,:]\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "\n",
    "#y_data = pd.DataFrame(y_total[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left = y_data.loc[y_data[:][0] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#left.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#right = y_data.loc[y_data[:][1] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#right.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward = y_data.loc[y_data[:][2] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "\n",
    "    sub_plt = axarr[int(i/plt_row), int(i%plt_col)]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_train[i].reshape(320, 320,3))\n",
    "    \n",
    "    label = np.argmax(y_train[i])\n",
    "                      \n",
    "    if label == 2 :\n",
    "        direction = 'left'\n",
    "    elif label == 1:\n",
    "        direction = 'right'\n",
    "    elif label == 0:\n",
    "        direction = 'forward'\n",
    "#     elif label == 3:\n",
    "#         direction = 'backward'\n",
    "                      \n",
    "    sub_plt_title = str(label) + \" : \" + direction\n",
    "    sub_plt.set_title(sub_plt_title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image size = 160 x 320\n",
    "def posla_net():\n",
    "    \n",
    "    # model setting\n",
    "    H = 320\n",
    "    W = 320\n",
    "    CH = 3\n",
    "\n",
    "    inputShape = (H, W, CH)\n",
    "\n",
    "    activation = 'relu'\n",
    "    keep_prob_conv = 0.25\n",
    "    keep_prob_dense = 0.5\n",
    "\n",
    "    #init = 'glorot_normal'\n",
    "    #init = 'he_normal'\n",
    "    init = 'he_uniform'\n",
    "    chanDim = -1\n",
    "    classes = 3\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # CONV => RELU => POOL\n",
    "    model.add(Conv2D(3, (3, 3), padding=\"valid\", input_shape=inputShape, kernel_initializer=init, activation=activation))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(9, (3, 3), padding=\"valid\", kernel_initializer=init, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(18, (3, 3), padding=\"valid\", kernel_initializer=init, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), padding=\"valid\", kernel_initializer=init, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(80, kernel_initializer=init, activation=activation))\n",
    "    model.add(Dropout(keep_prob_dense))\n",
    "    \n",
    "    model.add(Dense(15, kernel_initializer=init, activation=activation))\n",
    "    model.add(Dropout(keep_prob_dense))\n",
    "    \n",
    "    # softmax classifier\n",
    "    model.add(Dense(classes , activation = 'softmax'))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 318, 318, 3)       84        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 318, 318, 3)       12        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 159, 159, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 157, 157, 9)       252       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 78, 78, 9)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 76, 76, 18)        1476      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 38, 38, 18)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 36, 36, 32)        5216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 80)                829520    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                1215      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 48        \n",
      "=================================================================\n",
      "Total params: 837,823\n",
      "Trainable params: 837,817\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = posla_net()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils import plot_model\n",
    "plot_model(model, to_file= 'video_net_plot.png', show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 모델 파라미터 셋팅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "적은 수의 이미지 데이터가 존재할 경우 데이터를 늘리는 용도로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "# EPOCHS = 50\n",
    "# INIT_LR = 1e-3\n",
    "# BS = 32\n",
    "# split_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "INIT_LR = 1e-4\n",
    "BS = 256\n",
    "split_ratio = 0.2\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binary = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5600 samples, validate on 1400 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[80,15] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node dense_1/kernel/Initializer/random_uniform/RandomUniform (defined at <ipython-input-10-ae2ab2e4d0aa>:42)  = RandomUniform[T=DT_INT32, _class=[\"loc:@dense_1/kernel/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_1/kernel/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'dense_1/kernel/Initializer/random_uniform/RandomUniform', defined at:\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-f51137829256>\", line 1, in <module>\n    model = posla_net()\n  File \"<ipython-input-10-ae2ab2e4d0aa>\", line 42, in posla_net\n    model.add(Dense(15, kernel_initializer=init, activation=activation))\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\", line 474, in _method_wrapper\n    method(self, *args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py\", line 175, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 746, in __call__\n    self.build(input_shapes)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py\", line 944, in build\n    trainable=True)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 609, in add_weight\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\", line 639, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1977, in make_variable\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2437, in default_variable_creator\n    import_scope=import_scope)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 297, in __init__\n    constraint=constraint)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 409, in _init_from_args\n    initial_value() if init_from_fn else initial_value,\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1959, in <lambda>\n    shape, dtype=dtype, partition_info=partition_info)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 486, in __call__\n    shape, -limit, limit, dtype, seed=self.seed)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\", line 243, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 733, in random_uniform\n    name=name)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[80,15] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node dense_1/kernel/Initializer/random_uniform/RandomUniform (defined at <ipython-input-10-ae2ab2e4d0aa>:42)  = RandomUniform[T=DT_INT32, _class=[\"loc:@dense_1/kernel/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_1/kernel/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[80,15] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node dense_1/kernel/Initializer/random_uniform/RandomUniform}} = RandomUniform[T=DT_INT32, _class=[\"loc:@dense_1/kernel/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_1/kernel/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-34d4e901fd77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit_ratio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                  \u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2945\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`inputs` should be a list or tuple.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2947\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2948\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2949\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    467\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    736\u001b[0m       \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m       \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[80,15] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node dense_1/kernel/Initializer/random_uniform/RandomUniform (defined at <ipython-input-10-ae2ab2e4d0aa>:42)  = RandomUniform[T=DT_INT32, _class=[\"loc:@dense_1/kernel/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_1/kernel/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'dense_1/kernel/Initializer/random_uniform/RandomUniform', defined at:\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-f51137829256>\", line 1, in <module>\n    model = posla_net()\n  File \"<ipython-input-10-ae2ab2e4d0aa>\", line 42, in posla_net\n    model.add(Dense(15, kernel_initializer=init, activation=activation))\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\", line 474, in _method_wrapper\n    method(self, *args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py\", line 175, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 746, in __call__\n    self.build(input_shapes)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py\", line 944, in build\n    trainable=True)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 609, in add_weight\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\", line 639, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1977, in make_variable\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2437, in default_variable_creator\n    import_scope=import_scope)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 297, in __init__\n    constraint=constraint)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 409, in _init_from_args\n    initial_value() if init_from_fn else initial_value,\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1959, in <lambda>\n    shape, dtype=dtype, partition_info=partition_info)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 486, in __call__\n    shape, -limit, limit, dtype, seed=self.seed)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\", line 243, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 733, in random_uniform\n    name=name)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/frcnn1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[80,15] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node dense_1/kernel/Initializer/random_uniform/RandomUniform (defined at <ipython-input-10-ae2ab2e4d0aa>:42)  = RandomUniform[T=DT_INT32, _class=[\"loc:@dense_1/kernel/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_1/kernel/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hist = model.fit(x_train, y_train, \n",
    "                 epochs=EPOCHS, batch_size=BS, \n",
    "                 validation_split=split_ratio, \n",
    "                 verbose = 1\n",
    "                 ,callbacks=[reduce_lr]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.title('model loss')\n",
    "plt.plot(hist.history['loss'], label=\"loss\")\n",
    "plt.plot(hist.history['val_loss'], label=\"val_loss\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.ylim((0,2))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('model accuracy')\n",
    "plt.plot(hist.history['acc'], label=\"acc\")\n",
    "plt.plot(hist.history['val_acc'], label=\"val_acc\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.ylim((0.4, 1))\n",
    "\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 모델 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l_model = load_model('./model_data/VGG_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=BS)\n",
    "print('## evaluation loss and_metrics ##')\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat_idx = np.random.choice(x_test.shape[0], 10)\n",
    "xhat = x_test[xhat_idx]\n",
    "\n",
    "yhat_classes = model.predict_classes(xhat)\n",
    "\n",
    "for i in range(10):\n",
    "    print('True : ' + str(np.argmax(y_test[xhat_idx[i]])) + ', Predict : ' + str(yhat_classes[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 최종 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_total = np.vstack((x_train, x_test))\n",
    "y_total = np.vstack((y_train, y_test))\n",
    "\n",
    "print(x_total.shape)\n",
    "print(y_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "INIT_LR = 1e-4\n",
    "BS = 256\n",
    "split_ratio = 0.2\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist = model.fit(x_total, y_total, \n",
    "                 epochs=EPOCHS, batch_size=BS, \n",
    "                 #validation_split=split_ratio, \n",
    "                 verbose = 1\n",
    "                 ,callbacks=[reduce_lr]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=BS)\n",
    "print('## evaluation loss and_metrics ##')\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat_idx = np.random.choice(x_test.shape[0], 10)\n",
    "xhat = x_test[xhat_idx]\n",
    "\n",
    "yhat_classes = model.predict_classes(xhat)\n",
    "\n",
    "for i in range(10):\n",
    "    print('True : ' + str(np.argmax(y_test[xhat_idx[i]])) + ', Predict : ' + str(yhat_classes[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import model_from_yaml\n",
    "\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"motion_model_demo.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"motion_model_demo.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 62, 62, 3)         84        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 62, 62, 3)         12        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 31, 31, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 29, 29, 9)         252       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 14, 14, 9)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 12, 12, 18)        1476      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 6, 6, 18)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 4, 4, 32)          5216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 80)                10320     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 15)                1215      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 3)                 48        \n",
      "=================================================================\n",
      "Total params: 18,623\n",
      "Trainable params: 18,617\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
